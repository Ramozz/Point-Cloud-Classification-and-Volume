{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Reshape, Dropout\n",
    "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "#Reads hdf5 files\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "\n",
    "#multiplies 2 matricies\n",
    "def mat_mul(A, B):\n",
    "    return tf.matmul(A, B)\n",
    "\n",
    "#adds noice to some random points\n",
    "def jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n",
    "    B, N, C = batch_data.shape\n",
    "    print(B , N , C)\n",
    "    assert(clip > 0)\n",
    "    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1 * clip, clip)\n",
    "    jittered_data += batch_data\n",
    "    return jittered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0920 15:31:31.604472 140417225975552 deprecation_wrapper.py:119] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0920 15:31:31.608540 140417225975552 deprecation_wrapper.py:119] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0920 15:31:31.623465 140417225975552 deprecation_wrapper.py:119] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0920 15:31:31.980831 140417225975552 deprecation_wrapper.py:119] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0920 15:31:33.182535 140417225975552 deprecation_wrapper.py:119] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0920 15:31:33.910790 140417225975552 deprecation_wrapper.py:119] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0920 15:31:40.801735 140417225975552 deprecation.py:506] From /home/ramozz/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0920 15:31:40.806392 140417225975552 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0920 15:31:41.058784 140417225975552 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# number of points in each sample\n",
    "num_points = 2048\n",
    "\n",
    "# number of categories\n",
    "k = 7 # 0 big parallelepipeds, 1 small parallelepipeds , 2 small spheres, 3 big spheres, 4 cubes, 5 cylinders, 6 pyramids\n",
    "\n",
    "# define optimizer\n",
    "adam = optimizers.Adam(lr=0.005, decay=0.7)\n",
    "\n",
    "# Pointnet Architecture\n",
    "\n",
    "# Input Transformation net\n",
    "input_points = Input(shape=(num_points, 3))\n",
    "x = Convolution1D(64, 1, activation='relu',input_shape=(num_points, 3))(input_points)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(128, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(1024, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=num_points)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
    "input_T = Reshape((3, 3))(x)\n",
    "\n",
    "# Forward net\n",
    "g = Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "\n",
    "# Feature Transform net\n",
    "f = Convolution1D(64, 1, activation='relu')(g)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(128, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(1024, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = MaxPooling1D(pool_size=num_points)(f)\n",
    "f = Dense(512, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(256, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
    "feature_T = Reshape((64, 64))(f)\n",
    "\n",
    "# Forward net\n",
    "g = Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
    "g = Convolution1D(64, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(128, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(1024, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "\n",
    "# Global_feature\n",
    "global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
    "\n",
    "# Point_net_classification\n",
    "c = Dense(512, activation='relu')(global_feature)\n",
    "c = BatchNormalization()(c)\n",
    "c = Dropout(rate=0.7)(c)\n",
    "c = Dense(256, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Dropout(rate=0.7)(c)\n",
    "c = Dense(k, activation='softmax')(c)\n",
    "prediction = Flatten()(c)\n",
    "\n",
    "model = Model(inputs=input_points, outputs=prediction)\n",
    "\n",
    "# Compile classification model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded !\n"
     ]
    }
   ],
   "source": [
    "#Load pre-trained weights\n",
    "from keras.models import load_model\n",
    "\n",
    "model.load_weights('classification_weights 195.h5')\n",
    "print(\"Weights loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socket successfully created\n",
      "socket binded to 12348\n",
      "socket is listening\n",
      "Got connection from ('127.0.0.1', 40326)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40328)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40332)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40334)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40336)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40338)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40340)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40342)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40346)\n",
      "Analyse this pcd\n",
      "Got connection from ('127.0.0.1', 40350)\n",
      "Analyse this pcd\n"
     ]
    }
   ],
   "source": [
    "#reads te point cloud to be classified\n",
    "from pyntcloud import PyntCloud\n",
    "import numpy as np\n",
    "\n",
    "test_cloud = []\n",
    "cls = 0; #point cloud to be analysed\n",
    "\n",
    "#reads point cloud file to np.array list\n",
    "def ImportTarget():\n",
    "    file = \"cloud.pcd\"\n",
    "    data = PyntCloud.from_file(file)\n",
    "    cloud = data.xyz\n",
    "    test_cloud.append(cloud)\n",
    "    \n",
    "#sends predict result\n",
    "def kerasPredict(order):\n",
    "    target = np.array(test_cloud[order])\n",
    "    target = target.reshape(-1, num_points, 3)\n",
    "    pred = model.predict(target)\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = pred.tolist()\n",
    "    return pred\n",
    "\n",
    "#selects the three highest values of the predict classes\n",
    "def maxValues(): \n",
    "    maxvalue= 0\n",
    "    max1 = 0\n",
    "    maximus = np.empty([3]) # 3 probabilities\n",
    "    indices = np.empty([2]) # two most important labels\n",
    "    totaly = 0\n",
    "    totalc = True\n",
    "    i= 0\n",
    "    indice = 0\n",
    "\n",
    "    for pos in range (0,3):\n",
    "        for value in result: \n",
    "            if maxvalue < value and pos ==0 :\n",
    "                maxvalue= value\n",
    "                max1 = value\n",
    "                indice = i \n",
    "            elif maxvalue < value and pos ==1 and value != max1 :\n",
    "                maxvalue= value\n",
    "                max2 = value \n",
    "                indice= i\n",
    "            elif totalc:\n",
    "                totaly = totaly + value \n",
    "            i += 1\n",
    "\n",
    "        totalc = False\n",
    "        if(pos == 0):   \n",
    "            maximus[pos] = maxvalue\n",
    "            indices[pos] = indice\n",
    "        if(pos == 1):   \n",
    "            maximus[pos] = maxvalue\n",
    "            indices[pos] = indice\n",
    "        if(pos == 2):\n",
    "            maximus[pos] = totaly\n",
    "        i = 0\n",
    "        maxvalue = 0\n",
    "        indice = 0\n",
    "\n",
    "    maximus = np.around(maximus, decimals= 2)\n",
    "\n",
    "    #passing to string only the 3 highest positions\n",
    "    # 0 parallelepipeds, 1 spheres, 2 cubes, 3 cylinders, 4 pyramids\n",
    "    total1 = ' '.join(str(maximus[x]) for x in range(0,3)) \n",
    "    total2 = ' '.join(str(indices[y]) for y in range(0,2))\n",
    "    total = total1 + \" \" +  total2\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TCP python server\n",
    "\n",
    "# Socket library \n",
    "import socket                \n",
    "  \n",
    "# Socket object \n",
    "s = socket.socket()          \n",
    "print (\"Socket successfully created\")\n",
    "  \n",
    "# Reserve a port on your computer \n",
    "port = 12348              \n",
    "  \n",
    "# Binding to the port \n",
    "s.bind(('', port))         \n",
    "print (\"socket binded to %s\" %(port) )\n",
    "  \n",
    "# Socket into listening mode \n",
    "s.listen(5)      \n",
    "print (\"socket is listening\" )           \n",
    "  \n",
    "# True loop until we interrupt it or an error occurs \n",
    "while True: \n",
    "    # Stays until a connection is established   \n",
    "    connection, addr = s.accept()  \n",
    "    print ('Got connection from', addr )\n",
    "    \n",
    "    data = connection.recv(16)\n",
    "    my_decoded_str = data.decode()\n",
    "    #type(my_decoded_str) # ensure it is string representation\n",
    "    \n",
    "    #if some messsage is received\n",
    "    if data:\n",
    "        ImportTarget()\n",
    "        result = kerasPredict(cls)\n",
    "        cls += 1  #goes for the next pcd\n",
    "        total = maxValues()\n",
    "        print(my_decoded_str)\n",
    "        my_str = total\n",
    "        my_str_as_bytes = str.encode(my_str)\n",
    "        type(my_str_as_bytes) # ensure it is byte representation\n",
    "        data = 0;\n",
    "        # send a thank you message to the client.  \n",
    "        connection.send(my_str_as_bytes)\n",
    "\n",
    "# Close the connection with the client \n",
    "connection.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
